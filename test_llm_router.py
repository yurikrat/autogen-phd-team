#!/usr/bin/env python3
"""
Teste do LLM Router - Valida roteamento inteligente entre DeepSeek e OpenAI.
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# Carregar variÃ¡veis de ambiente
load_dotenv()

# Adicionar path
sys.path.insert(0, str(Path(__file__).parent))

from utils.llm_router import get_llm_router


def test_basic_call():
    """Teste 1: Chamada bÃ¡sica."""
    print("\n" + "=" * 80)
    print("ğŸ§ª TESTE 1: Chamada BÃ¡sica")
    print("=" * 80)
    
    router = get_llm_router()
    
    try:
        response = router.call("Responda apenas 'OK' para confirmar que estÃ¡ funcionando.")
        print(f"âœ… Resposta recebida: {response[:100]}")
        return True
    except Exception as e:
        print(f"âŒ Erro: {e}")
        return False


def test_multiple_calls():
    """Teste 2: MÃºltiplas chamadas."""
    print("\n" + "=" * 80)
    print("ğŸ§ª TESTE 2: MÃºltiplas Chamadas")
    print("=" * 80)
    
    router = get_llm_router()
    successes = 0
    
    for i in range(5):
        try:
            response = router.call(f"Diga apenas o nÃºmero {i+1}")
            print(f"âœ… Chamada {i+1}: {response[:50]}")
            successes += 1
        except Exception as e:
            print(f"âŒ Chamada {i+1} falhou: {e}")
    
    print(f"\nğŸ“Š Resultado: {successes}/5 chamadas bem-sucedidas")
    return successes >= 4  # Pelo menos 80% de sucesso


def test_message_format():
    """Teste 3: Formato de mensagens."""
    print("\n" + "=" * 80)
    print("ğŸ§ª TESTE 3: Formato de Mensagens")
    print("=" * 80)
    
    router = get_llm_router()
    
    # Teste com string
    try:
        response1 = router.call("Teste string")
        print(f"âœ… String: {response1[:50]}")
    except Exception as e:
        print(f"âŒ String falhou: {e}")
        return False
    
    # Teste com lista de mensagens
    try:
        messages = [
            {"role": "system", "content": "VocÃª Ã© um assistente Ãºtil."},
            {"role": "user", "content": "Teste lista"}
        ]
        response2 = router.call(messages)
        print(f"âœ… Lista: {response2[:50]}")
    except Exception as e:
        print(f"âŒ Lista falhou: {e}")
        return False
    
    return True


def test_with_crewai_agent():
    """Teste 4: IntegraÃ§Ã£o com CrewAI Agent."""
    print("\n" + "=" * 80)
    print("ğŸ§ª TESTE 4: IntegraÃ§Ã£o com CrewAI Agent")
    print("=" * 80)
    
    try:
        from crewai import Agent, Task, Crew
        from utils.llm_router import get_llm_router
        
        # Criar LLM Router
        llm = get_llm_router(temperature=0.7)
        
        # Criar agente
        agent = Agent(
            role="Test Agent",
            goal="Testar o LLM Router",
            backstory="VocÃª Ã© um agente de teste.",
            llm=llm,
            verbose=False
        )
        
        # Criar tarefa
        task = Task(
            description="Diga apenas 'Teste bem-sucedido'",
            expected_output="Uma confirmaÃ§Ã£o",
            agent=agent
        )
        
        # Executar crew
        crew = Crew(agents=[agent], tasks=[task], verbose=False)
        result = crew.kickoff()
        
        print(f"âœ… CrewAI executou com sucesso")
        print(f"   Resultado: {str(result)[:100]}")
        return True
        
    except Exception as e:
        print(f"âŒ Erro na integraÃ§Ã£o com CrewAI: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_error_handling():
    """Teste 5: Tratamento de erros."""
    print("\n" + "=" * 80)
    print("ğŸ§ª TESTE 5: Tratamento de Erros")
    print("=" * 80)
    
    router = get_llm_router()
    
    # Simular mensagem vazia (deve funcionar)
    try:
        response = router.call("")
        print(f"âœ… Mensagem vazia tratada: {response[:50]}")
    except Exception as e:
        print(f"âš ï¸  Mensagem vazia gerou erro (esperado): {str(e)[:100]}")
    
    return True


def main():
    """Executa todos os testes."""
    print("\n" + "=" * 80)
    print("ğŸš€ INICIANDO TESTES DO LLM ROUTER")
    print("=" * 80)
    
    # Verificar variÃ¡veis de ambiente
    if not os.getenv("DEEPSEEK_API_KEY"):
        print("âŒ DEEPSEEK_API_KEY nÃ£o configurada!")
        return False
    
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  OPENAI_API_KEY nÃ£o configurada (fallback nÃ£o funcionarÃ¡)")
    
    print("âœ… VariÃ¡veis de ambiente configuradas")
    
    # Executar testes
    results = {
        'Chamada BÃ¡sica': test_basic_call(),
        'MÃºltiplas Chamadas': test_multiple_calls(),
        'Formato de Mensagens': test_message_format(),
        'IntegraÃ§Ã£o CrewAI': test_with_crewai_agent(),
        'Tratamento de Erros': test_error_handling(),
    }
    
    # EstatÃ­sticas finais
    print("\n" + "=" * 80)
    print("ğŸ“Š ESTATÃSTICAS FINAIS")
    print("=" * 80)
    
    router = get_llm_router()
    router.print_stats()
    
    # Resumo dos testes
    print("\n" + "=" * 80)
    print("ğŸ“‹ RESUMO DOS TESTES")
    print("=" * 80)
    
    passed = sum(1 for result in results.values() if result)
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… PASSOU" if result else "âŒ FALHOU"
        print(f"{status}: {test_name}")
    
    print("\n" + "=" * 80)
    print(f"ğŸ¯ RESULTADO FINAL: {passed}/{total} testes passaram ({passed/total*100:.1f}%)")
    print("=" * 80)
    
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
