"""
Sistema de Valida√ß√£o Inteligente de Artefatos.
Garante que os artefatos criados fazem sentido para a tarefa.
"""

from typing import Dict, List, Any
from pathlib import Path
import json


class ArtifactValidator:
    """
    Valida se os artefatos criados fazem sentido para a tarefa solicitada.
    Funciona como um revisor humano experiente.
    """
    
    def __init__(self):
        self.validation_results = []
    
    def validate_artifacts_for_task(
        self,
        task: str,
        artifacts: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Valida se os artefatos criados s√£o adequados para a tarefa.
        
        Args:
            task: Descri√ß√£o da tarefa original
            artifacts: Lista de artefatos criados
        
        Returns:
            Resultado da valida√ß√£o com score e feedback
        """
        task_lower = task.lower()
        
        # Identificar tipo de tarefa
        task_type = self._identify_task_type(task_lower)
        
        # Validar artefatos baseado no tipo de tarefa
        validation = {
            "task_type": task_type,
            "artifacts_count": len(artifacts),
            "expected_artifacts": self._get_expected_artifacts(task_type, task_lower),
            "found_artifacts": [a["name"] for a in artifacts],
            "missing_critical": [],
            "unexpected": [],
            "quality_issues": [],
            "score": 0.0,
            "feedback": []
        }
        
        # Verificar artefatos esperados
        for expected in validation["expected_artifacts"]:
            found = any(
                expected["pattern"].lower() in a["name"].lower()
                or expected["pattern"].lower() in a.get("kind", "").lower()
                for a in artifacts
            )
            
            if not found and expected["critical"]:
                validation["missing_critical"].append(expected["name"])
                validation["feedback"].append(
                    f"‚ùå CR√çTICO: Faltando {expected['name']} - {expected['reason']}"
                )
        
        # Verificar qualidade dos artefatos
        for artifact in artifacts:
            quality_issues = self._check_artifact_quality(artifact, task_type)
            validation["quality_issues"].extend(quality_issues)
        
        # Calcular score
        validation["score"] = self._calculate_score(validation)
        
        # Gerar feedback geral
        if validation["score"] >= 0.9:
            validation["feedback"].insert(0, "‚úÖ EXCELENTE: Artefatos completos e de alta qualidade!")
        elif validation["score"] >= 0.7:
            validation["feedback"].insert(0, "‚úÖ BOM: Artefatos adequados, mas pode melhorar.")
        elif validation["score"] >= 0.5:
            validation["feedback"].insert(0, "‚ö†Ô∏è REGULAR: Artefatos b√°sicos, faltam componentes importantes.")
        else:
            validation["feedback"].insert(0, "‚ùå INSUFICIENTE: Artefatos n√£o atendem a tarefa adequadamente.")
        
        self.validation_results.append(validation)
        return validation
    
    def _identify_task_type(self, task_lower: str) -> str:
        """Identifica o tipo de tarefa baseado em palavras-chave."""
        if any(kw in task_lower for kw in ["api", "rest", "endpoint", "backend"]):
            return "api_backend"
        elif any(kw in task_lower for kw in ["frontend", "react", "vue", "interface", "ui"]):
            return "frontend"
        elif any(kw in task_lower for kw in ["banco", "database", "schema", "modelo"]):
            return "database"
        elif any(kw in task_lower for kw in ["deploy", "ci/cd", "docker", "kubernetes"]):
            return "devops"
        elif any(kw in task_lower for kw in ["documenta√ß√£o", "docs", "manual"]):
            return "documentation"
        elif any(kw in task_lower for kw in ["teste", "test", "qa"]):
            return "testing"
        elif any(kw in task_lower for kw in ["arquitetura", "design", "diagrama"]):
            return "architecture"
        else:
            return "general"
    
    def _get_expected_artifacts(self, task_type: str, task_lower: str) -> List[Dict]:
        """Retorna artefatos esperados baseado no tipo de tarefa."""
        expected = {
            "api_backend": [
                {"name": "C√≥digo da API", "pattern": ".py", "critical": True, "reason": "API precisa de c√≥digo"},
                {"name": "Documenta√ß√£o da API", "pattern": "api", "critical": True, "reason": "API precisa de docs"},
                {"name": "Testes", "pattern": "test", "critical": True, "reason": "API precisa de testes"},
                {"name": "Requirements", "pattern": "requirements", "critical": False, "reason": "Depend√™ncias devem estar documentadas"},
            ],
            "frontend": [
                {"name": "Componentes", "pattern": ".jsx", "critical": True, "reason": "Frontend precisa de componentes"},
                {"name": "Estilos", "pattern": ".css", "critical": True, "reason": "Frontend precisa de estilos"},
                {"name": "README", "pattern": "readme", "critical": False, "reason": "Instru√ß√µes de uso"},
            ],
            "database": [
                {"name": "Schema SQL", "pattern": ".sql", "critical": True, "reason": "Banco precisa de schema"},
                {"name": "Diagrama ER", "pattern": "diagram", "critical": True, "reason": "Banco precisa de modelo visual"},
                {"name": "Documenta√ß√£o", "pattern": ".md", "critical": False, "reason": "Explica√ß√£o do modelo"},
            ],
            "devops": [
                {"name": "Dockerfile", "pattern": "dockerfile", "critical": True, "reason": "Deploy precisa de container"},
                {"name": "CI/CD Config", "pattern": ".yml", "critical": True, "reason": "Automa√ß√£o precisa de pipeline"},
                {"name": "README", "pattern": "readme", "critical": False, "reason": "Instru√ß√µes de deploy"},
            ],
            "documentation": [
                {"name": "Documenta√ß√£o Principal", "pattern": ".md", "critical": True, "reason": "Docs precisam de conte√∫do"},
                {"name": "Exemplos", "pattern": "example", "critical": False, "reason": "Docs precisam de exemplos"},
            ],
            "testing": [
                {"name": "Testes", "pattern": "test", "critical": True, "reason": "QA precisa de testes"},
                {"name": "Relat√≥rio", "pattern": "report", "critical": False, "reason": "Resultados devem ser documentados"},
            ],
            "architecture": [
                {"name": "Diagrama", "pattern": "diagram", "critical": True, "reason": "Arquitetura precisa de visual"},
                {"name": "Documenta√ß√£o", "pattern": ".md", "critical": True, "reason": "Decis√µes devem ser documentadas"},
            ],
            "general": [
                {"name": "Documenta√ß√£o", "pattern": ".md", "critical": False, "reason": "Sempre √© bom ter docs"},
            ]
        }
        
        return expected.get(task_type, expected["general"])
    
    def _check_artifact_quality(self, artifact: Dict, task_type: str) -> List[str]:
        """Verifica qualidade de um artefato espec√≠fico."""
        issues = []
        
        # Verificar se arquivo existe
        path = artifact.get("path")
        if path and Path(path).exists():
            file_size = Path(path).stat().st_size
            
            # Arquivo muito pequeno pode ser vazio ou incompleto
            if file_size < 100:
                issues.append(f"‚ö†Ô∏è {artifact['name']}: Arquivo muito pequeno ({file_size} bytes) - pode estar incompleto")
            
            # Verificar conte√∫do se for texto
            if artifact.get("kind") in ["markdown", "json", "text", "python", "javascript"]:
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Verificar se tem conte√∫do m√≠nimo
                    if len(content.strip()) < 50:
                        issues.append(f"‚ö†Ô∏è {artifact['name']}: Conte√∫do muito curto - parece incompleto")
                    
                    # Verificar se JSON √© v√°lido
                    if artifact.get("kind") == "json":
                        try:
                            json.loads(content)
                        except json.JSONDecodeError:
                            issues.append(f"‚ùå {artifact['name']}: JSON inv√°lido")
                    
                    # Verificar se Markdown tem estrutura
                    if artifact.get("kind") == "markdown":
                        if "#" not in content:
                            issues.append(f"‚ö†Ô∏è {artifact['name']}: Markdown sem headers - falta estrutura")
                    
                    # Verificar se c√≥digo tem imports/fun√ß√µes
                    if artifact.get("kind") in ["python", "javascript"]:
                        if "def " not in content and "function " not in content and "class " not in content:
                            issues.append(f"‚ö†Ô∏è {artifact['name']}: C√≥digo sem fun√ß√µes/classes - parece incompleto")
                
                except Exception as e:
                    issues.append(f"‚ùå {artifact['name']}: Erro ao ler arquivo - {str(e)}")
        else:
            issues.append(f"‚ùå {artifact['name']}: Arquivo n√£o encontrado no caminho especificado")
        
        return issues
    
    def _calculate_score(self, validation: Dict) -> float:
        """Calcula score de qualidade dos artefatos (0.0 a 1.0)."""
        score = 1.0
        
        # Penalizar por artefatos cr√≠ticos faltando
        critical_missing = len(validation["missing_critical"])
        score -= critical_missing * 0.3
        
        # Penalizar por problemas de qualidade
        quality_issues = len(validation["quality_issues"])
        score -= quality_issues * 0.1
        
        # Bonificar por ter artefatos esperados
        expected_count = len(validation["expected_artifacts"])
        found_count = len(validation["found_artifacts"])
        if expected_count > 0:
            coverage = found_count / expected_count
            score *= coverage
        
        return max(0.0, min(1.0, score))
    
    def generate_improvement_suggestions(self, validation: Dict) -> List[str]:
        """Gera sugest√µes de melhoria baseado na valida√ß√£o."""
        suggestions = []
        
        for missing in validation["missing_critical"]:
            suggestions.append(f"üîß Criar {missing}")
        
        for issue in validation["quality_issues"]:
            if "muito pequeno" in issue or "muito curto" in issue:
                suggestions.append(f"üîß Expandir conte√∫do do arquivo mencionado")
            elif "JSON inv√°lido" in issue:
                suggestions.append(f"üîß Corrigir sintaxe do JSON")
            elif "sem headers" in issue:
                suggestions.append(f"üîß Adicionar estrutura com headers no Markdown")
            elif "sem fun√ß√µes" in issue:
                suggestions.append(f"üîß Implementar fun√ß√µes/classes no c√≥digo")
        
        return suggestions


# Inst√¢ncia global
_validator = None

def get_validator() -> ArtifactValidator:
    """Retorna inst√¢ncia singleton do validador."""
    global _validator
    if _validator is None:
        _validator = ArtifactValidator()
    return _validator

