# ğŸ¼ AutoGen PhD Team Orchestra - Dashboard Visual em Tempo Real

Sistema avanÃ§ado de execuÃ§Ã£o de time de agentes AutoGen (v0.4+) com:
- âœ… **PapÃ©is de TI "nÃ­vel PhD/Nobel"**
- âœ… **Sistema de ProvocaÃ§Ã£o e EvoluÃ§Ã£o** - Agentes se desafiam mutuamente
- âœ… **Dashboard Web em Tempo Real** - VisualizaÃ§Ã£o ao vivo da colaboraÃ§Ã£o
- âœ… **GrÃ¡fico de InteraÃ§Ãµes** - Mapa visual de quem estÃ¡ falando com quem
- âœ… **MÃ©tricas de Performance** - Acompanhar progresso e qualidade
- âœ… **Roteamento DinÃ¢mico** - Apenas agentes necessÃ¡rios sÃ£o ativados
- âœ… **Entrega de Artefatos** - Tudo salvo em `./runs/<timestamp>/`

## ğŸ¯ O Que Torna Este Sistema Ãšnico?

### 1. **Orquestra Colaborativa com ProvocaÃ§Ã£o**

Os agentes nÃ£o apenas executam tarefas - eles se **desafiam mutuamente** para elevar a qualidade:

- **Tech_Architect** questiona: *"VocÃª considerou a escalabilidade desta soluÃ§Ã£o para 10x o volume atual?"*
- **SecOps** ataca: *"Esta implementaÃ§Ã£o estÃ¡ protegida contra os OWASP Top 10?"*
- **QA_Engineer** desafia: *"Como vocÃª validaria esta funcionalidade em produÃ§Ã£o?"*
- **Performance_Engineer** provoca: *"Qual Ã© a complexidade algorÃ­tmica desta soluÃ§Ã£o?"*

Cada agente Ã© programado para **nÃ£o aceitar soluÃ§Ãµes medianas** e forÃ§ar melhorias contÃ­nuas.

### 2. **VisualizaÃ§Ã£o em Tempo Real**

Dashboard web moderno que mostra:

- **Mapa de InteraÃ§Ãµes**: Grafo visual de quem estÃ¡ falando com quem
- **Stream de Mensagens**: Conversas e desafios em tempo real
- **MÃ©tricas Ao Vivo**: Mensagens, artefatos, desafios, melhorias
- **Status dos Agentes**: Quem estÃ¡ ativo, quantas mensagens enviou
- **Artefatos Gerados**: Lista atualizada de arquivos criados

### 3. **Comportamento "PhD/Nobel"**

Cada agente segue princÃ­pios de excelÃªncia:

- **Clareza e PrecisÃ£o**: ComunicaÃ§Ã£o objetiva e estruturada
- **AnÃ¡lise de Riscos**: IdentificaÃ§Ã£o proativa de problemas
- **CritÃ©rios de Aceite**: ValidaÃ§Ã£o mensurÃ¡vel de entregas
- **Feedback ContÃ­nuo**: Progresso reportado constantemente
- **SeguranÃ§a by Default**: Prioridade em todas as decisÃµes
- **DecisÃµes AcionÃ¡veis**: RecomendaÃ§Ãµes prÃ¡ticas e implementÃ¡veis

## ğŸš€ Como Usar

### InstalaÃ§Ã£o RÃ¡pida

```bash
# 1. Clone o repositÃ³rio
git clone <URL_DO_REPOSITORIO>
cd autogen-phd-team

# 2. Crie ambiente virtual
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\Activate.ps1  # Windows

# 3. Instale dependÃªncias
pip install -r requirements.txt

# 4. Configure API key
cp .env.example .env
# Edite .env e adicione sua OPENAI_API_KEY
```

### ExecuÃ§Ã£o com Dashboard Visual

```bash
python team_runtime_visual.py "Sua tarefa aqui..."
```

O dashboard abrirÃ¡ automaticamente em `http://localhost:5000` e vocÃª verÃ¡:

- ğŸ¨ **Interface moderna** com tema dark
- ğŸ“Š **MÃ©tricas em tempo real** atualizando a cada segundo
- ğŸ’¬ **Stream de conversas** entre os agentes
- ğŸ”— **Grafo de interaÃ§Ãµes** mostrando colaboraÃ§Ã£o
- ğŸ“¦ **Lista de artefatos** sendo criados

### Exemplos de Tasks

**1. Projeto Backend Completo com ProvocaÃ§Ã£o:**
```bash
python team_runtime_visual.py "Criar serviÃ§o de reconciliaÃ§Ã£o Pix: API REST (FastAPI), Postgres, ETL diÃ¡rio, dashboard Metabase, CI/CD em Kubernetes; LGPD + OWASP. Entreguem todos os artefatos e desafiem-se mutuamente para garantir excelÃªncia."
```

**2. Arquitetura EscalÃ¡vel:**
```bash
python team_runtime_visual.py "Projetar arquitetura de microserviÃ§os para e-commerce com 1M de usuÃ¡rios simultÃ¢neos. Incluir: API Gateway, serviÃ§os, bancos, cache, filas, observabilidade. Tech_Architect e Performance_Engineer devem desafiar todas as decisÃµes."
```

**3. AnÃ¡lise de SeguranÃ§a Profunda:**
```bash
python team_runtime_visual.py "Realizar anÃ¡lise de seguranÃ§a OWASP Top 10 em aplicaÃ§Ã£o web, incluindo SAST, DAST, threat modeling e recomendaÃ§Ãµes de remediaÃ§Ã£o. SecOps deve atacar mentalmente cada componente."
```

## ğŸ­ Sistema de ProvocaÃ§Ã£o e EvoluÃ§Ã£o

### Como Funciona?

1. **Agentes Especializados**: Cada papel tem expertise especÃ­fica
2. **Desafios Constantes**: ApÃ³s cada entrega, outros agentes questionam
3. **Melhorias Iterativas**: SoluÃ§Ãµes sÃ£o refinadas em mÃºltiplas rodadas
4. **MÃ©tricas de Qualidade**: Dashboard rastreia desafios e melhorias

### Exemplos de ProvocaÃ§Ãµes Reais:

**Tech_Architect â†’ Backend_Dev:**
> "VocÃª considerou a escalabilidade desta soluÃ§Ã£o para 10x o volume atual? Como esta arquitetura se comporta em cenÃ¡rios de falha parcial?"

**SecOps â†’ Todos:**
> "Esta implementaÃ§Ã£o estÃ¡ protegida contra os OWASP Top 10? Como vocÃª garante que dados sensÃ­veis nÃ£o vazem nos logs?"

**QA_Engineer â†’ Developer:**
> "Como vocÃª validaria esta funcionalidade em produÃ§Ã£o? Quais cenÃ¡rios de edge case nÃ£o foram cobertos?"

**Performance_Engineer â†’ Backend_Dev:**
> "Qual Ã© a complexidade algorÃ­tmica desta soluÃ§Ã£o? Existem gargalos Ã³bvios que podem ser otimizados?"

## ğŸ“Š Dashboard - Recursos Visuais

### Tela Principal

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¼ AutoGen PhD Team Orchestra          [Status: Running]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          â”‚                                â”‚                 â”‚
â”‚  Agentes â”‚   Mapa de InteraÃ§Ãµes (Grafo)  â”‚    MÃ©tricas     â”‚
â”‚  Ativos  â”‚                                â”‚                 â”‚
â”‚          â”‚   â—‹â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â—‹             â”‚  Mensagens: 45  â”‚
â”‚  â— Orch  â”‚   â”‚      â”‚      â”‚             â”‚  Artefatos: 12  â”‚
â”‚  â— Tech  â”‚   â—‹â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â—‹             â”‚  Desafios: 8    â”‚
â”‚  â— Back  â”‚                                â”‚  Melhorias: 5   â”‚
â”‚  â— SecOpsâ”‚                                â”‚                 â”‚
â”‚          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚          â”‚                                â”‚  Artefatos      â”‚
â”‚          â”‚   Stream de Mensagens          â”‚  Gerados:       â”‚
â”‚          â”‚                                â”‚                 â”‚
â”‚          â”‚  [Orch] Coordenando task...   â”‚  âœ“ api_spec.md  â”‚
â”‚          â”‚  [Tech] ğŸ¯ DESAFIO: VocÃª      â”‚  âœ“ schema.sql   â”‚
â”‚          â”‚         considerou...          â”‚  âœ“ docker.yml   â”‚
â”‚          â”‚  [Back] Implementando...       â”‚  âœ“ README.md    â”‚
â”‚          â”‚  [SecOps] âš ï¸ Risco detectado  â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cores e Indicadores

- ğŸŸ¢ **Verde**: Agente ativo, mensagem normal
- ğŸŸ¡ **Amarelo**: Desafio lanÃ§ado
- ğŸ”µ **Azul**: Melhoria implementada
- ğŸ”´ **Vermelho**: Erro ou risco identificado
- âš¡ **Pulsante**: Agente processando

## ğŸ§© Arquitetura do Sistema

### Componentes Principais

1. **team_runtime_visual.py**: Runtime principal com dashboard integrado
2. **orchestration.py**: Sistema de provocaÃ§Ã£o e evoluÃ§Ã£o
3. **dashboard/app.py**: Servidor Flask com WebSocket
4. **dashboard/templates/dashboard.html**: Interface web moderna
5. **roles.py**: Mensagens de sistema "PhD/Nobel" aprimoradas
6. **routing.py**: SeleÃ§Ã£o dinÃ¢mica de papÃ©is
7. **tools/**: Ferramentas de I/O e gerenciamento de artefatos

### Fluxo de ExecuÃ§Ã£o

```
1. UsuÃ¡rio executa task
2. Dashboard inicia em background
3. Agentes sÃ£o selecionados dinamicamente
4. ExecuÃ§Ã£o comeÃ§a com RoundRobinGroupChat
5. Cada mensagem Ã© enviada ao dashboard via WebSocket
6. Agentes se provocam e melhoram soluÃ§Ãµes
7. Artefatos sÃ£o salvos e exibidos em tempo real
8. Finalizer consolida e gera MANIFEST.md
9. Dashboard continua acessÃ­vel para revisÃ£o
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar NÃ­vel de ProvocaÃ§Ã£o

Edite `orchestration.py` para controlar intensidade dos desafios:

```python
# Mais agressivo
CHALLENGE_FREQUENCY = "always"  # Desafia em toda mensagem

# Moderado (padrÃ£o)
CHALLENGE_FREQUENCY = "often"   # Desafia frequentemente

# Suave
CHALLENGE_FREQUENCY = "sometimes"  # Desafia ocasionalmente
```

### Customizar Dashboard

Edite `dashboard/templates/dashboard.html` para:
- Mudar cores e tema
- Adicionar grÃ¡ficos personalizados
- Modificar layout
- Adicionar filtros e buscas

### Adicionar Novos PapÃ©is com ProvocaÃ§Ã£o

1. Adicione em `roles.py`:
```python
"Meu_Papel": phd_nobel(
    prefix="VocÃª Ã© o **Meu Papel**...",
    domain_expectations="..."
)
```

2. Adicione comportamento de desafio em `orchestration.py`:
```python
ENHANCED_SYSTEM_MESSAGES["Meu_Papel"] = """
...
**Comportamento de Desafio:**
- Questione X
- Exija Y
- Proponha Z
"""
```

3. Adicione palavras-chave em `routing.py`:
```python
KEYWORDS["Meu_Papel"] = ["palavra1", "palavra2", ...]
```

## ğŸ“ˆ MÃ©tricas e KPIs

O dashboard rastreia:

- **Total de Mensagens**: Quantidade de interaÃ§Ãµes
- **Total de Artefatos**: Arquivos gerados
- **Desafios LanÃ§ados**: Quantas vezes agentes provocaram outros
- **Melhorias Feitas**: Quantas otimizaÃ§Ãµes foram implementadas
- **Agentes Ativos**: Quantos papÃ©is estÃ£o participando
- **Tempo de ExecuÃ§Ã£o**: DuraÃ§Ã£o total da task

## ğŸ› Troubleshooting

### Dashboard nÃ£o abre

```bash
# Verifique se Flask estÃ¡ instalado
pip install flask flask-socketio python-socketio

# Verifique se porta 5000 estÃ¡ livre
lsof -i :5000  # Linux/Mac
netstat -ano | findstr :5000  # Windows
```

### Agentes nÃ£o se provocam

- Verifique se `orchestration.py` estÃ¡ sendo importado
- Confirme que `inject_challenge_behavior()` estÃ¡ sendo chamado
- Aumente `max_turns` para dar mais rodadas de interaÃ§Ã£o

### Dashboard nÃ£o atualiza

- Verifique console do navegador (F12) para erros WebSocket
- Confirme que `emit_event()` estÃ¡ sendo chamado
- Reinicie o servidor do dashboard

## ğŸ“ Boas PrÃ¡ticas

### Para Tasks Complexas

1. **Seja EspecÃ­fico**: Quanto mais detalhes, melhor a orquestraÃ§Ã£o
2. **Mencione Desafios**: PeÃ§a explicitamente que agentes se provoquem
3. **Defina CritÃ©rios**: Especifique mÃ©tricas de qualidade esperadas
4. **DÃª Tempo**: Use `max_turns` alto para tasks complexas

### Para MÃ¡xima Qualidade

1. **Ative PapÃ©is de Qualidade**: QA, Performance, SecOps
2. **Force RevisÃµes**: PeÃ§a que Tech_Architect revise tudo
3. **Exija Testes**: Solicite cobertura de testes
4. **PeÃ§a DocumentaÃ§Ã£o**: Sempre inclua docs e diagramas

## ğŸ“ LicenÃ§a

MIT License - Use, modifique e distribua livremente.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Ãreas de interesse:

- Novos papÃ©is especializados
- Melhorias no dashboard
- Algoritmos de provocaÃ§Ã£o mais sofisticados
- IntegraÃ§Ã£o com ferramentas externas
- Testes automatizados

## ğŸ“§ Suporte

Para dÃºvidas, problemas ou sugestÃµes, abra uma issue no repositÃ³rio.

---

**Desenvolvido com â¤ï¸ e muita provocaÃ§Ã£o construtiva usando AutoGen v0.4+**

ğŸ¼ *"A excelÃªncia nÃ£o Ã© um ato, mas um hÃ¡bito de desafiar constantemente."*

